{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fd565a4",
   "metadata": {},
   "source": [
    "# Novelty Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68148ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from crewai_tools import BaseTool\n",
    "import os\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from anthropic import AnthropicBedrock\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a1bbb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoveltyAgent(BaseTool):\n",
    "    name:str = \"novelty-agent\"\n",
    "    description:str = \"\"\n",
    "        \n",
    "    def _run(self, argument: dict) -> list[str]:\n",
    "        pass\n",
    "    \n",
    "    def extract_references(self, file):\n",
    "        print(\"============================\")\n",
    "        print(\"Extracting References (Step: 1/7)\")\n",
    "        print(\"============================\")\n",
    "        \n",
    "        references_dict = {}\n",
    "        references = file.get(\"references\", [])\n",
    "        for ref in references:\n",
    "            title = ref.get(\"title\")\n",
    "            abstract = ref.get(\"abstract\")\n",
    "            if title and abstract:\n",
    "                references_dict[title] = abstract\n",
    "        print(references_dict)\n",
    "        return references_dict\n",
    "\n",
    "    def generate_search(self, client, argument):\n",
    "        print(\"============================\")\n",
    "        print(\"GENERATING SEARCH PHRASES (Step: 2/7)\")\n",
    "        print(\"============================\")\n",
    "        # Generate Keywords\n",
    "        search_phrases = []\n",
    "\n",
    "        # First Search Phrase \n",
    "        messages = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f'''\n",
    "            Given the abstract of an academic paper below, generate a search phrase of less than 10 words to find related papers in the field. Return ONLY this phrase\n",
    "            This phrase should be useful for searching for similar papers in academic databases. Use general terms that reflect domain-specific field knowledge to \n",
    "            enable a fruitful search. \n",
    "\n",
    "            Abstract: {argument['abstract']}\n",
    "            '''\n",
    "        }]\n",
    "\n",
    "        keywords = client.messages.create(\n",
    "            model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "            max_tokens=128,\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        content = keywords.content\n",
    "        if isinstance(content, list) and len(content) > 0:\n",
    "            content = content[0].text\n",
    "        else:\n",
    "            content = str(content)\n",
    "\n",
    "        final_kw = content.strip()\n",
    "        print(f\"First phrase: {final_kw}\\n\")\n",
    "        search_phrases.append(final_kw)\n",
    "        \n",
    "        # Second Search Phrase\n",
    "        messages = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f'''\n",
    "            Given the abstract of an academic paper and a previously generated search phrase, create a new, broader search phrase of less than 10 words. \n",
    "            This new phrase should expand the search scope to include related concepts or methodologies not covered by the first phrase. \n",
    "            Return ONLY this new phrase.\n",
    "\n",
    "            Abstract: {argument['abstract']}\n",
    "            Previous search phrase: {search_phrases}\n",
    "            '''\n",
    "        }]\n",
    "\n",
    "        keywords = client.messages.create(\n",
    "            model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "            max_tokens=128,\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        content = keywords.content\n",
    "        if isinstance(content, list) and len(content) > 0:\n",
    "            content = content[0].text\n",
    "        else:\n",
    "            content = str(content)\n",
    "\n",
    "        final_kw = content.strip()\n",
    "        print(f\"Second phrase: {final_kw}\\n\")\n",
    "        search_phrases.append(final_kw)\n",
    "        \n",
    "        # Third Search Phrase\n",
    "        messages = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f'''\n",
    "            Given an academic paper abstract and two previously generated search phrases, create a final, even broader search phrase of less than 10 words. \n",
    "            This phrase should capture the most general concepts related to the paper's field of study, potentially including interdisciplinary connections. \n",
    "            The goal is to cast the widest possible net for related research. Return ONLY this new phrase.\n",
    "\n",
    "            Abstract: {argument['abstract']}\n",
    "            Previous search phrase: {search_phrases}\n",
    "            '''\n",
    "        }]\n",
    "\n",
    "        keywords = client.messages.create(\n",
    "            model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "            max_tokens=128,\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        content = keywords.content\n",
    "        if isinstance(content, list) and len(content) > 0:\n",
    "            content = content[0].text\n",
    "        else:\n",
    "            content = str(content)\n",
    "\n",
    "        final_kw = content.strip()\n",
    "        print(f\"Third phrase: {final_kw}\\n\")\n",
    "        search_phrases.append(final_kw)\n",
    "        return search_phrases\n",
    "\n",
    "    def search_related_papers(self, client, argument, search_phrases):\n",
    "        print(\"============================\")\n",
    "        print(\"SEARCHING FOR RELATED PAPERS (Step: 3/7)\")\n",
    "        print(\"============================\")\n",
    "        search_url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
    "        api_key = os.getenv(\"X_API_KEY\")\n",
    "        \n",
    "        related_papers = {}\n",
    "        if not api_key:\n",
    "            print(\"API key is missing. Please set the X_API_KEY environment variable.\")\n",
    "        headers = {\n",
    "            \"x-api-key\": api_key,\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "        \n",
    "        # Search 1:\n",
    "        params = {\n",
    "            \"query\": search_phrases[0],\n",
    "            \"fields\": \"title,abstract\",\n",
    "            \"limit\": 10  # Number of results to retrieve\n",
    "        }\n",
    "\n",
    "        response = requests.get(search_url, headers=headers, params=params)\n",
    "        if response.status_code == 200:\n",
    "            response_json = response.json()\n",
    "            if 'data' in response_json:\n",
    "                entries = response_json['data']\n",
    "                print(f'Query 1 produced {len(entries)} results')\n",
    "                related_papers.update({entry['title']: entry['abstract'] for entry in entries if 'title' in entry and 'abstract' in entry})\n",
    "            else:\n",
    "                print(\"No 'data' key in the response. Response structure:\")\n",
    "                print(json.dumps(response_json, indent=2))\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        \n",
    "        # Search 2:\n",
    "        time.sleep(1)\n",
    "        params = {\n",
    "            \"query\": search_phrases[1],\n",
    "            \"fields\": \"title,abstract\",\n",
    "            \"limit\": 10  # Number of results to retrieve\n",
    "        }\n",
    "\n",
    "        response = requests.get(search_url, headers=headers, params=params)\n",
    "        if response.status_code == 200:\n",
    "            response_json = response.json()\n",
    "            if 'data' in response_json:\n",
    "                entries = response_json['data']\n",
    "                print(f'Query 2 produced {len(entries)} results')\n",
    "                related_papers.update({entry['title']: entry['abstract'] for entry in entries if 'title' in entry and 'abstract' in entry})\n",
    "            else:\n",
    "                print(\"No 'data' key in the response. Response structure:\")\n",
    "                print(json.dumps(response_json, indent=2))\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        # Search 3:\n",
    "        time.sleep(1)\n",
    "        params = {\n",
    "            \"query\": search_phrases[2],\n",
    "            \"fields\": \"title,abstract\",\n",
    "            \"limit\": 10  # Number of results to retrieve\n",
    "        }\n",
    "\n",
    "        response = requests.get(search_url, headers=headers, params=params)\n",
    "        if response.status_code == 200:\n",
    "            response_json = response.json()\n",
    "            if 'data' in response_json:\n",
    "                entries = response_json['data']\n",
    "                print(f'Query 3 produced {len(entries)} results')\n",
    "                related_papers.update({entry['title']: entry['abstract'] for entry in entries if 'title' in entry and 'abstract' in entry})\n",
    "            else:\n",
    "                print(\"No 'data' key in the response. Response structure:\")\n",
    "                print(json.dumps(response_json, indent=2))\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        print(\"Titles of Related Papers Found:\")\n",
    "        print(list(related_papers.keys()))\n",
    "        return related_papers\n",
    "    \n",
    "    def remove_cited(self, cited_papers, related_papers):\n",
    "        print(\"============================\")\n",
    "        print(\"REMOVING CITATIONS FROM RECOMMENDED PAPERS (Step: 4/7)\")\n",
    "        print(\"============================\")\n",
    "        \n",
    "        # Take in list of cited papers\n",
    "        # papers.toUpper()\n",
    "        # see if any cited paper equals temp(toUpper(related_papers))\n",
    "        # if so, remove from dict\n",
    "        cited_titles = [paper.upper() for paper in cited_papers]\n",
    "        filtered_papers = {title: abstract for title, abstract in related_papers.items() if title.upper() not in cited_titles}\n",
    "        \n",
    "        print(f\"Number of cited papers found in recommendation set: {len(related_papers.keys()) - len(filtered_papers.keys())}\")\n",
    "        return filtered_papers\n",
    "        \n",
    "    def filter_papers(self, client, argument, related_papers):\n",
    "        print(\"============================\")\n",
    "        print(\"FILTERING FOR RELEVANT PAPERS (Step: 5/7)\")\n",
    "        print(\"============================\")\n",
    "        \n",
    "        filtered_dict = {}\n",
    "        \n",
    "        for title, abstract in related_papers.items():\n",
    "            messages = [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\":f'''\n",
    "                Assess the relevancy of the following paper to the core paper. Be strict in your assessment\n",
    "                and only consider it relevant if it closely relates to the core concept.\n",
    "                If the core paper and the paper to assess are the same thing, your assessment is \"Irrelevant\"\n",
    "                Core Paper:\n",
    "                Title: {argument['title']}\n",
    "                Abstract: {argument['abstract']}\n",
    "                \n",
    "                Paper to Assess:\n",
    "                Title: {title}\n",
    "                Abstract: {abstract}\n",
    "                \n",
    "                Provide your assessment as a single word: \"Relevant\" or \"Irrelevant\".\n",
    "                Only output the single word with no other text or explanation\n",
    "                '''\n",
    "            }]\n",
    "            \n",
    "            response = client.messages.create(\n",
    "                model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "                max_tokens=2,\n",
    "                messages=messages\n",
    "            )\n",
    "            content = response.content\n",
    "            if isinstance(content, list) and len(content) > 0:\n",
    "                content = content[0].text\n",
    "            else:\n",
    "                content = str(content)\n",
    "\n",
    "            res = content.strip()\n",
    "            if res.lower() == \"relevant\":\n",
    "                filtered_dict[title] = abstract\n",
    "            \n",
    "        print(f\"Original length: {len(related_papers.keys())}\")\n",
    "        print(f\"Filtered length: {len(filtered_dict.keys())}\")\n",
    "        \n",
    "        return filtered_dict\n",
    "\n",
    "    \n",
    "    def assess_novelty(self, client, argument, filtered_dict):\n",
    "        print(\"============================\")\n",
    "        print(\"ASSESSING NOVELTY (Step: 6/7)\")\n",
    "        print(\"============================\")\n",
    "        \n",
    "        \n",
    "        # Loop through for novelty assessment.\n",
    "        results = []\n",
    "        for title, abstract in filtered_dict.items():\n",
    "            print(f\"Comparing with: {title} \\n\")\n",
    "            messages = [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f'''\n",
    "                As a novelty assessor, compare the following proposed academic paper abstract with an existing paper's abstract.\n",
    "                Evaluate whether the new paper presents a significantly novel idea or approach compared to the existing paper.\n",
    "                \n",
    "                New Paper: \n",
    "                Title: {argument['title']}\n",
    "                Abstract: {argument['abstract']}\n",
    "                \n",
    "                Existing Paper\n",
    "                Title: {title}\n",
    "                Abstract: {abstract}\n",
    "                \n",
    "                Please consider:\n",
    "                1. A brief comparison of the key ideas, methods, or findings\n",
    "                2. An assessment of the novelty of the new paper compared to the existing one.\n",
    "                3. A clear decision: Is the new paper sufficiently novel compared to this existing paper? Answer with \"Novel\" or \"Not Novel\".\n",
    "                \n",
    "                However, in your response, simply provide a decision and a 2-3 sentence justification for your decision.\n",
    "                \n",
    "                Format your response as follows:\n",
    "                \n",
    "                Decision: [Novel/Not Novel]\n",
    "                \n",
    "                Justification: [Your Assessment Here]\n",
    "                '''\n",
    "            }]\n",
    "            response = client.messages.create(\n",
    "                model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "                max_tokens=256,\n",
    "                messages=messages\n",
    "            )\n",
    "            \n",
    "            # Format response to text only:\n",
    "            response = response.content\n",
    "            if isinstance(response, list) and len(response) > 0:\n",
    "                response = response[0].text\n",
    "            else:\n",
    "                response = str(response)\n",
    "\n",
    "            response = response.strip()\n",
    "            results.append({\n",
    "                'existing_title': title,\n",
    "                'assessment': response\n",
    "            })\n",
    "            print(f\"{response}\\n\")\n",
    "            print('-----------------------------------------')\n",
    "            \n",
    "        return results\n",
    "        \n",
    "    ### Make final step to summarize the entire novelty assessment into a single decision with explanation\n",
    "    def summarize_results(self, client, results):\n",
    "        print(\"============================\")\n",
    "        print(\"SUMMARIZING RESULTS (Step: 7/7)\")\n",
    "        print(\"============================\")\n",
    "        \n",
    "        messages = [{\n",
    "            'role': 'user',\n",
    "            'content': f'''\n",
    "                Given the following novelty assessment results, please summarize whether the proposed paper is novel or not. If any of the comparisons deem the paper as NOT NOVEL, \n",
    "                start the summary with ‘NOT NOVEL’, followed by an explanation that includes the title of the conflicting paper(s). If the paper is considered NOVEL, start the summary \n",
    "                with ‘NOVEL’, and then provide a brief justification of what makes it novel.\n",
    "\n",
    "                Here are the assessment results:\n",
    "                {results}\n",
    "            '''\n",
    "        }]\n",
    "        response = client.messages.create(\n",
    "            model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "            max_tokens=256,\n",
    "            messages=messages\n",
    "        )\n",
    "        # Format response to text only:\n",
    "        response = response.content\n",
    "        if isinstance(response, list) and len(response) > 0:\n",
    "            response = response[0].text\n",
    "        else:\n",
    "            response = str(response)\n",
    "\n",
    "        response = response.strip()\n",
    "        print(f\"FINAL ASSESSMENT: \\n{response}\\n\")\n",
    "        return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4231dab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model, API keys\n",
    "## Semantic Scholar\n",
    "## Claude\n",
    "model_id = \"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
   
    "## MARG Paper\n",
    "marg_title = \"MARG: Multi-Agent Review Generation for Scientific Papers\"\n",
    "marg_abstract = \"We study the ability of LLMs to generate feedback for scientific papers and develop MARG, a feedback generation approach using multiple LLM instances that engage in internal discussion. By distributing paper text across agents, MARG can consume the full text of papers beyond the input length limitations of the base LLM, and by specializing agents and incorporating sub-tasks tailored to different comment types (experiments, clarity, impact) it improves the helpfulness and specificity of feedback. In a user study, baseline methods using GPT-4 were rated as producing generic or very generic comments more than half the time, and only 1.7 comments per paper were rated as good overall in the best baseline. Our system substantially improves the ability of GPT-4 to generate specific and helpful feedback, reducing the rate of generic comments from 60% to 29% and generating 3.7 good comments per paper (a 2.2x improvement).\"\n",
    "marg = {\n",
    "    'title': marg_title,\n",
    "    'abstract': marg_abstract\n",
    "}\n",
    "## Pawin Paper\n",
    "pawin_title = \"MISTI: Metadata-Informed Scientific Text and Image Representation through Contrastive Learning\"\n",
    "pawin_abstract = \"In scientific publications, automatic representations of figures and their captions can be used in NLP, computer vision, and information retrieval tasks. Contrastive learning has proven effective for creating such joint representations for natural scenes, but its application to scientific imagery and descriptions remains under-explored. Recent open-access publication datasets provide an opportunity to understand the effectiveness of this technique as well as evaluate the usefulness of additional metadata, which are available only in the scientific context. Here, we introduce MISTI, a novel model that uses contrastive learning to simultaneously learn the representation of figures, captions, and metadata, such as a paper’s title, sections, and curated concepts from the PubMed Open Access Subset. We evaluate our model on multiple information retrieval tasks, showing substantial improvements over baseline models. Notably, incorporating metadata doubled retrieval performance, achieving a Recall@1 of 30% on a 70K-item caption retrieval task. We qualitatively explore how metadata can be used to strategically retrieve distinctive representations of the same concept but for different sections, such as introduction and results. Additionally, we show that our model seamlessly handles out-of-domain tasks related to image segmentation. We share our dataset and methods (https://github.com/Khempawin/scientificimage-caption-pair/tree/section-attr) and outline future research directions.\"\n",
    "pawin = {\n",
    "    'title': pawin_title,\n",
    "    'abstract': pawin_abstract\n",
    "}\n",
    "## Non-Novel Test Case\n",
    "non_novel_title = \"An Evaluation of Machine Learning Models for Predicting Stock Market Movements\"\n",
    "non_novel_abstract = \"Predicting stock market movements is a challenging task due to the market’s inherent volatility and complexity. In this paper, we evaluate the performance of various machine learning models in forecasting stock prices. Using a historical stock price dataset, we apply machine learning techniques such as Support Vector Machines (SVM), Random Forest, and Neural Networks to predict future trends. Our findings reveal that these models can achieve an accuracy rate of approximately 85%, with Neural Networks showing the best performance. This study offers a comparative analysis of different machine learning algorithms in the context of stock market prediction.\"\n",
    "non_novel = {\n",
    "    'title': non_novel_title,\n",
    "    'abstract': non_novel_abstract\n",
    "}\n",
    "related_paper = {\n",
    "    'title': \"A Comprehensive Study on the Impact of Machine Learning Algorithms in Predicting Stock Market Trends\",\n",
    "    'abstract': \"The stock market is a complex and dynamic system that presents significant challenges for accurate prediction. This study explores the efficacy of machine learning algorithms in predicting stock market trends. We utilize a dataset comprising historical stock prices and apply various machine learning techniques, including Support Vector Machines (SVM), Random Forest, and Neural Networks, to predict future stock prices. The results indicate that these models can achieve a prediction accuracy of up to 85%, with Neural Networks outperforming the other methods. This research contributes to the field by providing a detailed comparative analysis of machine learning models in the context of stock market prediction.\"\n",
    "}\n",
    "\n",
    "#test = NoveltyAgent()\n",
    "#novelty_assessment = test.assess_novelty(client, proposed_paper, related_paper)\n",
    "\n",
    "# Test Paper Extraction\n",
    "pawin_citations = ['S-CLIP: Semi-supervised Vision-Language Learning using Few Specialist Captions','Conditioned Image Retrieval for Fashion using Contrastive Learning and CLIP-based Features', 'Towards the generalization of contrastive self-supervised learning', ' A survey on contrastive selfsupervised learning', 'Automated brain image classification based on vgg-16 and transfer learning', 'Extracting figures and captions from scientific publications']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "deb04792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "GENERATING SEARCH PHRASES (Step: 2/7)\n",
      "============================\n",
      "First phrase: Contrastive learning scientific figures captions metadata retrieval\n",
      "\n",
      "Second phrase: Multimodal representation learning for scientific publications and information retrieval\n",
      "\n",
      "Third phrase: Integrating multimodal data for scientific knowledge representation and retrieval\n",
      "\n",
      "============================\n",
      "SEARCHING FOR RELATED PAPERS (Step: 3/7)\n",
      "============================\n",
      "Query 1 produced 10 results\n",
      "Error: 429 - {\"message\": \"Too Many Requests. Please wait and try again or apply for a key for higher rate limits. https://www.semanticscholar.org/product/api#api-key-form\", \"code\": \"429\"}\n",
      "Query 3 produced 2 results\n",
      "Titles of Related Papers Found:\n",
      "['MISTI: Metadata-Informed Scientific Text and Image Representation through Contrastive Learning', 'Learning and Reasoning for Cultural Metadata Quality: Coupling Symbolic AI and Machine Learning over a Semantic Web Knowledge Graph to Support Museum Curators in Improving the Quality of Cultural Metadata and Information Retrieval', 'SciMMIR: Benchmarking Scientific Multi-modal Information Retrieval', 'S-CLIP: Semi-supervised Vision-Language Learning using Few Specialist Captions', 'Information Retrieval and Machine Learning Methods for Academic Expert Finding', 'Summarizing figures, tables, and algorithms in scientific publications to augment search results', 'ACL-Fig: A Dataset for Scientific Figure Classification', 'Rethinking Privacy in Machine Learning Pipelines from an Information Flow Control Perspective', 'A Molecular Multimodal Foundation Model Associating Molecule Graphs with Natural Language', 'SciFig: A Scientific Figure Dataset for Figure Understanding', 'TCM Intelligent Recommendation Based on Multimodal Knowledge Graph Attention Network', 'Research and advanced technology for digital libraries : 12th European Conference, ECDL 2008, Aarhus, Denmark, September 14-19, 2008 : proceedings']\n",
      "============================\n",
      "REMOVING CITATIONS FROM RECOMMENDED PAPERS (Step: 4/7)\n",
      "============================\n",
      "Number of cited papers found in recommendation set: 1\n",
      "============================\n",
      "FILTERING FOR RELEVANT PAPERS (Step: 5/7)\n",
      "============================\n",
      "Original length: 11\n",
      "Filtered length: 5\n",
      "============================\n",
      "ASSESSING NOVELTY (Step: 6/7)\n",
      "============================\n",
      "Comparing with: SciMMIR: Benchmarking Scientific Multi-modal Information Retrieval \n",
      "\n",
      "Decision: Novel\n",
      "\n",
      "Justification: While both papers focus on multi-modal representation learning for scientific images and text, MISTI introduces a novel approach by incorporating additional metadata into the contrastive learning process. This inclusion of metadata, such as paper titles, sections, and curated concepts, significantly distinguishes MISTI from the existing SciMMIR benchmark. Moreover, MISTI's demonstrated performance improvements and its ability to handle out-of-domain tasks like image segmentation further establish its novelty in the field of scientific image-text representation learning.\n",
      "\n",
      "-----------------------------------------\n",
      "Comparing with: Summarizing figures, tables, and algorithms in scientific publications to augment search results \n",
      "\n",
      "Decision: Novel\n",
      "\n",
      "Justification: While both papers deal with improving search and retrieval of scientific document elements, the new paper (MISTI) introduces a novel approach using contrastive learning to create joint representations of figures, captions, and metadata. This is a significant advancement over the existing paper, which focuses on generating synopses for document elements. Additionally, MISTI's incorporation of metadata and its application to multiple information retrieval tasks, including out-of-domain image segmentation, represent substantial innovations not present in the existing work.\n",
      "\n",
      "-----------------------------------------\n",
      "Comparing with: ACL-Fig: A Dataset for Scientific Figure Classification \n",
      "\n",
      "Decision: Novel\n",
      "\n",
      "Justification: While both papers deal with scientific figures, their approaches and objectives are significantly different. The new paper (MISTI) focuses on creating joint representations of figures, captions, and metadata using contrastive learning, which is a novel approach in the scientific domain. In contrast, the existing paper (ACL-Fig) primarily focuses on building a dataset for figure classification. MISTI's incorporation of metadata and its application to multiple information retrieval tasks, including out-of-domain tasks, represents a substantial advancement over the more narrowly focused ACL-Fig work.\n",
      "\n",
      "-----------------------------------------\n",
      "Comparing with: A Molecular Multimodal Foundation Model Associating Molecule Graphs with Natural Language \n",
      "\n",
      "Decision: Novel\n",
      "\n",
      "Justification: While both papers use contrastive learning for multimodal representations, MISTI focuses specifically on scientific imagery and text, incorporating unique metadata like paper sections and curated concepts. This specialized approach for scientific content, along with the demonstrated improvements in retrieval tasks and ability to handle out-of-domain image segmentation, represents a novel contribution distinct from the broader molecular-focused model in the existing paper.\n",
      "\n",
      "-----------------------------------------\n",
      "Comparing with: SciFig: A Scientific Figure Dataset for Figure Understanding \n",
      "\n",
      "Decision: Novel\n",
      "\n",
      "Justification: While both papers focus on scientific figures, MISTI introduces a novel approach by using contrastive learning to create joint representations of figures, captions, and metadata. The inclusion of metadata, particularly from the PubMed Open Access Subset, and the application to multiple information retrieval tasks represent significant advancements over the SciFig dataset. Moreover, MISTI's ability to handle out-of-domain tasks and its demonstrated performance improvements in retrieval tasks indicate a substantial leap forward in scientific figure understanding and representation.\n",
      "\n",
      "-----------------------------------------\n",
      "============================\n",
      "SUMMARIZING RESULTS (Step: 7/7)\n",
      "============================\n",
      "FINAL ASSESSMENT: \n",
      "NOVEL\n",
      "\n",
      "The proposed paper, MISTI, is considered novel based on the assessment results. The key factors contributing to its novelty are:\n",
      "\n",
      "1. Unique approach: MISTI introduces a novel method of using contrastive learning to create joint representations of scientific figures, captions, and metadata. This approach is not present in any of the compared existing works.\n",
      "\n",
      "2. Incorporation of metadata: Unlike existing papers, MISTI integrates additional metadata such as paper titles, sections, and curated concepts into the contrastive learning process. This significantly distinguishes it from other works in the field.\n",
      "\n",
      "3. Versatility and performance: MISTI demonstrates improved performance in various information retrieval tasks and shows the ability to handle out-of-domain tasks like image segmentation. This versatility is not seen in the compared papers.\n",
      "\n",
      "4. Specialized focus: While some existing works focus on broader topics or specific tasks (e.g., molecular models, figure classification), MISTI specializes in scientific imagery and text representation learning, filling a unique niche in the field.\n",
      "\n",
      "5. Advancement over existing benchmarks: MISTI represents a substantial leap forward compared to existing benchmarks like SciMMIR\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Order for running:\n",
    "    0. Collect all references from the original paper\n",
    "    1. Generate Search Phrases\n",
    "    2. Query Semantic Scholar for recommended papers\n",
    "    3. Remove cited papers from the list\n",
    "    4. Remove irrelevant papers from the list\n",
    "    5. Assess the original paper's novelty relative to the recommended papers.\n",
    "    6. Summarize the results\n",
    "'''\n",
    "novel = NoveltyAgent()\n",
    "argument = pawin\n",
    "cited_papers = pawin_citations\n",
    "#cited_papers = novel.extract_references(json_path)\n",
    "search_phrases = novel.generate_search(client, argument)\n",
    "related_papers = novel.search_related_papers(client, argument, search_phrases)\n",
    "final_related_papers = novel.remove_cited(cited_papers, related_papers)\n",
    "filtered_papers = novel.filter_papers(client, argument, final_related_papers)\n",
    "novelty_assessment = novel.assess_novelty(client, argument, filtered_papers)\n",
    "summarized_results = novel.summarize_results(client, novelty_assessment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7fb650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
