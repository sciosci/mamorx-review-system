{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fd565a4",
   "metadata": {},
   "source": [
    "# Novelty Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68148ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from crewai_tools import BaseTool\n",
    "import os\n",
    "import boto3\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "from anthropic import AnthropicBedrock\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a1bbb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NoveltyAgent(BaseTool):\n",
    "    name:str = \"novelty-agent\"\n",
    "    description:str = \"\"\n",
    "        \n",
    "    def _run(self, argument: dict) -> list[str]:\n",
    "        pass\n",
    "    \n",
    "    def generate_search(self, client, argument):\n",
    "        print(\"============================\")\n",
    "        print(\"GENERATING SEARCH PHRASES\")\n",
    "        print(\"============================\")\n",
    "        # Generate Keywords\n",
    "        search_phrases = []\n",
    "\n",
    "        # First Search Phrase \n",
    "        messages = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f'''\n",
    "            Given the abstract of an academic paper below, generate a search phrase of less than 10 words to find related papers in the field. Return ONLY this phrase\n",
    "            This phrase should be useful for searching for similar papers in academic databases. Use general terms that reflect domain-specific field knowledge to \n",
    "            enable a fruitful search. \n",
    "\n",
    "            Abstract: {argument['abstract']}\n",
    "            '''\n",
    "        }]\n",
    "\n",
    "        keywords = client.messages.create(\n",
    "            model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "            max_tokens=128,\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        content = keywords.content\n",
    "        if isinstance(content, list) and len(content) > 0:\n",
    "            content = content[0].text\n",
    "        else:\n",
    "            content = str(content)\n",
    "\n",
    "        final_kw = content.strip()\n",
    "        print(f\"First phrase: {final_kw}\\n\")\n",
    "        search_phrases.append(final_kw)\n",
    "        \n",
    "        # Second Search Phrase\n",
    "        messages = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f'''\n",
    "            Given the abstract of an academic paper and a previously generated search phrase, create a new, broader search phrase of less than 10 words. \n",
    "            This new phrase should expand the search scope to include related concepts or methodologies not covered by the first phrase. \n",
    "            Return ONLY this new phrase.\n",
    "\n",
    "            Abstract: {argument['abstract']}\n",
    "            Previous search phrase: {search_phrases}\n",
    "            '''\n",
    "        }]\n",
    "\n",
    "        keywords = client.messages.create(\n",
    "            model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "            max_tokens=128,\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        content = keywords.content\n",
    "        if isinstance(content, list) and len(content) > 0:\n",
    "            content = content[0].text\n",
    "        else:\n",
    "            content = str(content)\n",
    "\n",
    "        final_kw = content.strip()\n",
    "        print(f\"Second phrase: {final_kw}\\n\")\n",
    "        search_phrases.append(final_kw)\n",
    "        \n",
    "        # Third Search Phrase\n",
    "        messages = [{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f'''\n",
    "            Given an academic paper abstract and two previously generated search phrases, create a final, even broader search phrase of less than 10 words. \n",
    "            This phrase should capture the most general concepts related to the paper's field of study, potentially including interdisciplinary connections. \n",
    "            The goal is to cast the widest possible net for related research. Return ONLY this new phrase.\n",
    "\n",
    "            Abstract: {argument['abstract']}\n",
    "            Previous search phrase: {search_phrases}\n",
    "            '''\n",
    "        }]\n",
    "\n",
    "        keywords = client.messages.create(\n",
    "            model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "            max_tokens=128,\n",
    "            messages=messages\n",
    "        )\n",
    "\n",
    "        content = keywords.content\n",
    "        if isinstance(content, list) and len(content) > 0:\n",
    "            content = content[0].text\n",
    "        else:\n",
    "            content = str(content)\n",
    "\n",
    "        final_kw = content.strip()\n",
    "        print(f\"Third phrase: {final_kw}\\n\")\n",
    "        search_phrases.append(final_kw)\n",
    "        return search_phrases\n",
    "\n",
    "    def search_related_papers(self, client, argument, search_phrases):\n",
    "        print(\"============================\")\n",
    "        print(\"SEARCHING FOR RELATED PAPERS\")\n",
    "        print(\"============================\")\n",
    "        search_url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
    "        api_key = os.getenv(\"X_API_KEY\")\n",
    "        \n",
    "        related_papers = {}\n",
    "        if not api_key:\n",
    "            print(\"API key is missing. Please set the X_API_KEY environment variable.\")\n",
    "        headers = {\n",
    "            \"x-api-key\": api_key,\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "        \n",
    "        # Search 1:\n",
    "        params = {\n",
    "            \"query\": search_phrases[0],\n",
    "            \"fields\": \"title,abstract\",\n",
    "            \"limit\": 10  # Number of results to retrieve\n",
    "        }\n",
    "\n",
    "        response = requests.get(search_url, headers=headers, params=params)\n",
    "        if response.status_code == 200:\n",
    "            response_json = response.json()\n",
    "            if 'data' in response_json:\n",
    "                entries = response_json['data']\n",
    "                print(f'Query 1 produced {len(entries)} results')\n",
    "                related_papers.update({entry['title']: entry['abstract'] for entry in entries if 'title' in entry and 'abstract' in entry})\n",
    "            else:\n",
    "                print(\"No 'data' key in the response. Response structure:\")\n",
    "                print(json.dumps(response_json, indent=2))\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        \n",
    "        # Search 2:\n",
    "        time.sleep(1)\n",
    "        params = {\n",
    "            \"query\": search_phrases[1],\n",
    "            \"fields\": \"title,abstract\",\n",
    "            \"limit\": 10  # Number of results to retrieve\n",
    "        }\n",
    "\n",
    "        response = requests.get(search_url, headers=headers, params=params)\n",
    "        if response.status_code == 200:\n",
    "            response_json = response.json()\n",
    "            if 'data' in response_json:\n",
    "                entries = response_json['data']\n",
    "                print(f'Query 2 produced {len(entries)} results')\n",
    "                related_papers.update({entry['title']: entry['abstract'] for entry in entries if 'title' in entry and 'abstract' in entry})\n",
    "            else:\n",
    "                print(\"No 'data' key in the response. Response structure:\")\n",
    "                print(json.dumps(response_json, indent=2))\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        # Search 3:\n",
    "        time.sleep(1)\n",
    "        params = {\n",
    "            \"query\": search_phrases[2],\n",
    "            \"fields\": \"title,abstract\",\n",
    "            \"limit\": 10  # Number of results to retrieve\n",
    "        }\n",
    "\n",
    "        response = requests.get(search_url, headers=headers, params=params)\n",
    "        if response.status_code == 200:\n",
    "            response_json = response.json()\n",
    "            if 'data' in response_json:\n",
    "                entries = response_json['data']\n",
    "                print(f'Query 3 produced {len(entries)} results')\n",
    "                related_papers.update({entry['title']: entry['abstract'] for entry in entries if 'title' in entry and 'abstract' in entry})\n",
    "            else:\n",
    "                print(\"No 'data' key in the response. Response structure:\")\n",
    "                print(json.dumps(response_json, indent=2))\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "        print(\"Titles of Related Papers Found:\")\n",
    "        print(list(related_papers.keys()))\n",
    "        return related_papers\n",
    "    \n",
    "    def filter_papers(self, client, argument, related_papers):\n",
    "        print(\"============================\")\n",
    "        print(\"FILTERING FOR RELEVANT PAPERS\")\n",
    "        print(\"============================\")\n",
    "        \n",
    "        filtered_dict = {}\n",
    "        \n",
    "        for title, abstract in related_papers.items():\n",
    "            messages = [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\":f'''\n",
    "                Assess the relevancy of the following paper to the core paper. Be strict in your assessment\n",
    "                and only consider it relevant if it closely relates to the core concept.\n",
    "                If the core paper and the paper to assess are the same thing, your assessment is \"Irrelevant\"\n",
    "                Core Paper:\n",
    "                Title: {argument['title']}\n",
    "                Abstract: {argument['abstract']}\n",
    "                \n",
    "                Paper to Assess:\n",
    "                Title: {title}\n",
    "                Abstract: {abstract}\n",
    "                \n",
    "                Provide your assessment as a single word: \"Relevant\" or \"Irrelevant\".\n",
    "                Only output the single word with no other text or explanation\n",
    "                '''\n",
    "            }]\n",
    "            \n",
    "            response = client.messages.create(\n",
    "                model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "                max_tokens=2,\n",
    "                messages=messages\n",
    "            )\n",
    "            content = response.content\n",
    "            if isinstance(content, list) and len(content) > 0:\n",
    "                content = content[0].text\n",
    "            else:\n",
    "                content = str(content)\n",
    "\n",
    "            res = content.strip()\n",
    "            if res.lower() == \"relevant\":\n",
    "                filtered_dict[title] = abstract\n",
    "            \n",
    "        print(f\"Original length: {len(related_papers.keys())}\")\n",
    "        print(f\"Filtered length: {len(filtered_dict.keys())}\")\n",
    "        \n",
    "        return filtered_dict\n",
    "\n",
    "    \n",
    "    def assess_novelty(self, client, argument, filtered_dict):\n",
    "        print(\"============================\")\n",
    "        print(\"ASSESSING NOVELTY\")\n",
    "        print(\"============================\")\n",
    "        \n",
    "        \n",
    "        # Loop through for novelty assessment.\n",
    "        results = []\n",
    "        for title, abstract in filtered_dict.items():\n",
    "            print(f\"Comparing with: {title} \\n\")\n",
    "            messages = [{\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f'''\n",
    "                As a novelty assessor, compare the following proposed academic paper abstract with an existing paper's abstract.\n",
    "                Evaluate whether the new paper presents a significantly novel idea or approach compared to the existing paper.\n",
    "                \n",
    "                New Paper: \n",
    "                Title: {argument['title']}\n",
    "                Abstract: {argument['abstract']}\n",
    "                \n",
    "                Existing Paper\n",
    "                Title: {title}\n",
    "                Abstract: {abstract}\n",
    "                \n",
    "                Please consider:\n",
    "                1. A brief comparison of the key ideas, methods, or findings\n",
    "                2. An assessment of the novelty of the new paper compared to the existing one.\n",
    "                3. A clear decision: Is the new paper sufficiently novel compared to this existing paper? Answer with \"Novel\" or \"Not Novel\".\n",
    "                \n",
    "                However, in your response, simply provide a decision and a 2-3 sentence justification for your decision.\n",
    "                \n",
    "                Format your response as follows:\n",
    "                \n",
    "                Decision: [Novel/Not Novel]\n",
    "                \n",
    "                Justification: [Your Assessment Here]\n",
    "                '''\n",
    "            }]\n",
    "            response = client.messages.create(\n",
    "                model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "                max_tokens=256,\n",
    "                messages=messages\n",
    "            )\n",
    "            \n",
    "            # Format response to text only:\n",
    "            response = response.content\n",
    "            if isinstance(response, list) and len(response) > 0:\n",
    "                response = response[0].text\n",
    "            else:\n",
    "                response = str(response)\n",
    "\n",
    "            response = response.strip()\n",
    "            results.append({\n",
    "                'existing_title': title,\n",
    "                'assessment': response\n",
    "            })\n",
    "            print(f\"{response}\\n\")\n",
    "            print('-----------------------------------------')\n",
    "            \n",
    "        return results\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4231dab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model, API keys\n",
    "## Semantic Scholar\n",
    "os.environ['X_API_KEY'] = 'FcuPcoxxWC3ePxBABTLvkyWxqvt7v9h32sDBO4ug'\n",
    "## Claude\n",
    "model_id = \"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
    "client = AnthropicBedrock(\n",
    "        aws_access_key='AKIA2UC3AYP2UVT7W4UE',  \n",
    "        aws_secret_key='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',  \n",
    "        aws_region='us-west-2'\n",
    "    )\n",
    "## Paper\n",
    "marg_title = \"MARG: Multi-Agent Review Generation for Scientific Papers\"\n",
    "marg_abstract = \"We study the ability of LLMs to generate feedback for scientific papers and develop MARG, a feedback generation approach using multiple LLM instances that engage in internal discussion. By distributing paper text across agents, MARG can consume the full text of papers beyond the input length limitations of the base LLM, and by specializing agents and incorporating sub-tasks tailored to different comment types (experiments, clarity, impact) it improves the helpfulness and specificity of feedback. In a user study, baseline methods using GPT-4 were rated as producing generic or very generic comments more than half the time, and only 1.7 comments per paper were rated as good overall in the best baseline. Our system substantially improves the ability of GPT-4 to generate specific and helpful feedback, reducing the rate of generic comments from 60% to 29% and generating 3.7 good comments per paper (a 2.2x improvement).\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "deb04792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================\n",
      "GENERATING SEARCH PHRASES\n",
      "============================\n",
      "First phrase: LLM-based scientific paper feedback generation techniques\n",
      "\n",
      "Second phrase: LLM multi-agent systems for document analysis and feedback\n",
      "\n",
      "Third phrase: Language models for academic research and peer review processes\n",
      "\n",
      "============================\n",
      "SEARCHING FOR RELATED PAPERS\n",
      "============================\n",
      "Query 1 produced 10 results\n",
      "Error: 429 - {\"message\": \"Too Many Requests. Please wait and try again or apply for a key for higher rate limits. https://www.semanticscholar.org/product/api#api-key-form\", \"code\": \"429\"}\n",
      "Query 3 produced 10 results\n",
      "Titles of Related Papers Found:\n",
      "['LLM Based Generation of Item-Description for Recommendation System', 'Citation-Enhanced Generation for LLM-based Chatbots', 'TestART: Improving LLM-based Unit Test via Co-evolution of Automated Generation and Repair Iteration', 'A LLM-Based Ranking Method for the Evaluation of Automatic Counter-Narrative Generation', 'One-step Reach: LLM-based Keyword Generation for Sponsored Search Advertising', 'Enhancing LLM-based Test Generation for Hard-to-Cover Branches via Program Analysis', 'When LLM-based Code Generation Meets the Software Development Process', 'LLM-based Test-driven Interactive Code Generation: User Study and Empirical Evaluation', 'Lusifer: LLM-based User SImulated Feedback Environment for online Recommender systems', 'MatPlotAgent: Method and Evaluation for LLM-Based Agentic Scientific Data Visualization', 'Democratizing Knowledge Creation Through Human-AI Collaboration in Academic Peer Review', 'Message in a Bottle: Expert Readers, English Language Arts, and New Directions for Writing Studies.', 'Named Entity Recognition for peer-review disambiguation in academic publishing', 'Investigating Fairness Disparities in Peer Review: A Language Model Enhanced Approach', 'Adapting an Interdisciplinary Learning Health System Framework for Academic Health Centers: A Scoping Review', 'Publish with AUTOGEN or Perish? Some Pitfalls to Avoid in the Pursuit of Academic Enhancement via Personalized Large Language Models', 'Research Integrity Enhancement: Integration of Post-Publication Peer Review to Alleviate Artificial Intelligence-Generated Research Misconduct', 'Peer Review as A Multi-Turn and Long-Context Dialogue with Role-Based Interactions', 'Partnering with insiders: A review of peer models across community‐engaged research, education and social care', 'From human writing to artificial intelligence generated text: examining the prospects and potential threats of ChatGPT in academic writing.']\n",
      "============================\n",
      "FILTERING FOR RELEVANT PAPERS\n",
      "============================\n",
      "Original length: 20\n",
      "Filtered length: 6\n",
      "============================\n",
      "ASSESSING NOVELTY\n",
      "============================\n",
      "Comparing with: When LLM-based Code Generation Meets the Software Development Process \n",
      "\n",
      "Decision: Novel\n",
      "\n",
      "Justification: While both papers explore multi-agent LLM systems, they address fundamentally different tasks and domains. The new paper (MARG) focuses on generating feedback for scientific papers, while the existing paper (LCG) targets software development processes. MARG's novel contribution lies in its approach to overcoming input length limitations and generating specific, helpful feedback for academic papers, which is distinct from LCG's focus on code generation and software engineering practices.\n",
      "\n",
      "-----------------------------------------\n",
      "Comparing with: Democratizing Knowledge Creation Through Human-AI Collaboration in Academic Peer Review \n",
      "\n",
      "Decision: Novel\n",
      "\n",
      "Justification: While both papers discuss AI's role in academic review processes, the new paper (MARG) presents a concrete, implemented system for generating paper feedback using multiple LLM instances. Unlike the existing paper, which offers a broad overview and speculation about future impacts, MARG provides specific technical details, experimental results, and quantitative improvements over baseline methods. This represents a significant advancement from theoretical discussion to practical application in the field of AI-assisted academic review.\n",
      "\n",
      "-----------------------------------------\n",
      "Comparing with: Named Entity Recognition for peer-review disambiguation in academic publishing \n",
      "\n",
      "Decision: Novel\n",
      "\n",
      "Justification: While both papers aim to improve the academic review process, they take fundamentally different approaches. The existing paper focuses on named entity recognition to annotate review comments, while MARG introduces a novel multi-agent LLM approach for generating review feedback. MARG's method of distributing paper content across multiple agents to overcome input limitations and its focus on generating specific, helpful feedback represents a significant advancement in automated review systems compared to the existing paper's annotation-based approach.\n",
      "\n",
      "-----------------------------------------\n",
      "Comparing with: Investigating Fairness Disparities in Peer Review: A Language Model Enhanced Approach \n",
      "\n",
      "Decision: Novel\n",
      "\n",
      "Justification: While both papers use language models to analyze or assist with scientific paper review, their approaches and goals are significantly different. The new paper (MARG) focuses on developing a multi-agent system to generate specific and helpful feedback for scientific papers, addressing input length limitations and improving comment quality. In contrast, the existing paper investigates fairness disparities in peer review using language models as an analytical tool. The MARG system's novel approach to feedback generation represents a distinct and innovative contribution to the field.\n",
      "\n",
      "-----------------------------------------\n",
      "Comparing with: Publish with AUTOGEN or Perish? Some Pitfalls to Avoid in the Pursuit of Academic Enhancement via Personalized Large Language Models \n",
      "\n",
      "Decision: Novel\n",
      "\n",
      "Justification: The new paper (MARG) presents a novel approach to generating feedback for scientific papers using multiple LLM instances, which is distinct from the existing paper's focus on ethical considerations and potential pitfalls of using AI in academic publishing. MARG introduces a specific technical solution to overcome LLM input limitations and improve feedback quality, while the existing paper primarily discusses broader implications and challenges. This represents a significant advancement in the practical application of AI to academic processes.\n",
      "\n",
      "-----------------------------------------\n",
      "Comparing with: Peer Review as A Multi-Turn and Long-Context Dialogue with Role-Based Interactions \n",
      "\n",
      "Decision: Novel\n",
      "\n",
      "Justification: While both papers address LLM-based peer review, MARG introduces a novel multi-agent approach that overcomes input length limitations and improves feedback quality through specialized agents and subtasks. The existing paper focuses on simulating the entire peer review process as a multi-turn dialogue, whereas MARG specifically targets generating high-quality, specific feedback. MARG's demonstrated improvements in reducing generic comments and increasing good feedback represent a significant advancement in the practical application of LLMs to scientific paper review.\n",
      "\n",
      "-----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "novel = NoveltyAgent()\n",
    "\n",
    "argument = {\n",
    "    'title': marg_title,\n",
    "    'abstract': marg_abstract\n",
    "}\n",
    "\n",
    "search_phrases = novel.generate_search(client, argument)\n",
    "related_papers = novel.search_related_papers(client, argument, search_phrases)\n",
    "filtered_papers = novel.filter_papers(client, argument, related_papers)\n",
    "novelty_assessment = novel.assess_novelty(client, argument, filtered_papers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9dc326",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
