{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bradleysides/anaconda3/lib/python3.11/site-packages/pydantic/_internal/_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "* 'smart_union' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for ChatBedrock\n__root__\n  Error raised by bedrock service: Did not find region_name, please add an environment variable `AWS_DEFAULT_REGION` which contains it, or pass `region_name` as a named parameter. (type=value_error)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m ss_check, ss_recommend, ss_keyword_search \u001b[38;5;241m=\u001b[39m SS_check(), SS_recommend(), SS_keyword_search()\n\u001b[1;32m     16\u001b[0m model_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manthropic.claude-3-5-sonnet-20240620-v1:0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 17\u001b[0m llm \u001b[38;5;241m=\u001b[39m load_model(model_id)\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Define your agents\u001b[39;00m\n\u001b[1;32m     20\u001b[0m researcher \u001b[38;5;241m=\u001b[39m Agent(\n\u001b[1;32m     21\u001b[0m   role\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRetriever\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     22\u001b[0m   goal\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtry to retrieve 10 related papers of the given paper, and assess its novelty\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     25\u001b[0m   tools\u001b[38;5;241m=\u001b[39m[paper_read_tool, ss_check, ss_recommend, ss_keyword_search]\n\u001b[1;32m     26\u001b[0m )\n",
      "File \u001b[0;32m~/Research/Fall-24/CrewAI_review_system/ai_reviewer/model.py:28\u001b[0m, in \u001b[0;36mload_model\u001b[0;34m(model_id)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(model_id:\u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m     27\u001b[0m     load_dotenv()\n\u001b[0;32m---> 28\u001b[0m     llm \u001b[38;5;241m=\u001b[39m ChatBedrock(\n\u001b[1;32m     29\u001b[0m         model_id \u001b[38;5;241m=\u001b[39m model_id\n\u001b[1;32m     30\u001b[0m         )\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m llm\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/langchain_core/load/serializable.py:113\u001b[0m, in \u001b[0;36mSerializable.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    112\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\"\"\"\u001b[39;00m\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pydantic/v1/main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[0;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[1;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[0;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[0;31mValidationError\u001b[0m: 1 validation error for ChatBedrock\n__root__\n  Error raised by bedrock service: Did not find region_name, please add an environment variable `AWS_DEFAULT_REGION` which contains it, or pass `region_name` as a named parameter. (type=value_error)"
     ]
    }
   ],
   "source": [
    "from crewai import Crew, Process, Agent, Task\n",
    "from model import load_model, list_avail_models\n",
    "from SemanticScholar import SemanticScholar, SS_keyword_search, SS_recommend, SS_check\n",
    "from crewai_tools import FileReadTool, TXTSearchTool\n",
    "import os\n",
    "\n",
    "# Initialize tools\n",
    "paper_path = \"../data/The complementary contributions of academia and industry to AI research.txt\"\n",
    "paper_not_in_ss = \"../data/paper not avail.txt\"\n",
    "\n",
    "paper_read_tool = FileReadTool(file_path=paper_not_in_ss)\n",
    "# ss_tool = SemanticScholar()\n",
    "ss_check, ss_recommend, ss_keyword_search = SS_check(), SS_recommend(), SS_keyword_search()\n",
    "\n",
    "\n",
    "model_id = \"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
    "llm = load_model(model_id)\n",
    "\n",
    "# Define your agents\n",
    "researcher = Agent(\n",
    "  role='Retriever',\n",
    "  goal='try to retrieve 10 related papers of the given paper, and assess its novelty',\n",
    "  backstory='An experienced researcher with great knowledge base in research area',\n",
    "  llm=llm,\n",
    "  tools=[paper_read_tool, ss_check, ss_recommend, ss_keyword_search]\n",
    ")\n",
    "\n",
    "# Define your tasks\n",
    "research_task = Task(\n",
    "    description=\"\"\"\n",
    "    Task: Access the paper using 'paper_read_tool', \n",
    "    Check if the paper is in Semantic Scholar database with 'ss_check',\n",
    "    If it is, then use 'ss_recommend' to get titles and abstracts of related papers,\n",
    "    If not, extract keywords of the paper and use 'ss_keyword_search' to get titles and abstracts.\n",
    "    After you have them, assess the novelty of input paper compared to other retrieved related papers.\n",
    "    Remember if somehow ss_recommend or ss_keyword_search does not work, try it again.\n",
    "    \"\"\",\n",
    "    agent=researcher, \n",
    "    expected_output=\"\"\"\n",
    "    the tools you are using,\n",
    "    the method you use to retrieve related papers,\n",
    "    the keyword you used to search if you do,\n",
    "    the retrieved paper titles,\n",
    "    and the novelty assessment of input paper\n",
    "    \"\"\"\n",
    "    )\n",
    "# Form the crew with a sequential process\n",
    "report_crew = Crew(\n",
    "  agents=[researcher],\n",
    "  tasks=[research_task],\n",
    "  process=Process.sequential\n",
    ")\n",
    "\n",
    "# Execute the crew\n",
    "result = report_crew.kickoff()\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['In many applications, attitude estimation algorithms rely mainly on magnetic and inertial measurements from MARG sensors (consisting of a magnetometer, a gyroscope, and an accelerometer). One of the main challenges facing these algorithms is that the accelerometer measures both gravity and an unknown external acceleration, while these algorithms assume that the accelerometer measures only the gravity. In this letter, an attitude estimation algorithm on the special orthogonal group SO(3) is designed, considering the external acceleration as an unknown input with direct feedthrough to the output, with a local approximation approach. The proposed algorithm is validated through Monte Carlo simulations and real datasets, demonstrating better accuracy and enhanced performance than existing solutions.', 'In this paper, we present the FIU MARG Dataset (FIUMARGDB) of signals from the tri-axial accelerometer, gyroscope, and magnetometer contained in a low-cost miniature magnetic–angular rate–gravity (MARG) sensor module (also known as magnetic inertial measurement unit, MIMU) for the evaluation of MARG orientation estimation algorithms. The dataset contains 30 files resulting from different volunteer subjects executing manipulations of the MARG in areas with and without magnetic distortion. Each file also contains reference (“ground truth”) MARG orientations (as quaternions) determined by an optical motion capture system during the recording of the MARG signals. The creation of FIUMARGDB responds to the increasing need for the objective comparison of the performance of MARG orientation estimation algorithms, using the same inputs (accelerometer, gyroscope, and magnetometer signals) recorded under varied circumstances, as MARG modules hold great promise for human motion tracking applications. This dataset specifically addresses the need to study and manage the degradation of orientation estimates that occur when MARGs operate in regions with known magnetic field distortions. To our knowledge, no other dataset with these characteristics is currently available. FIUMARGDB can be accessed through the URL indicated in the conclusions section. It is our hope that the availability of this dataset will lead to the development of orientation estimation algorithms that are more resilient to magnetic distortions, for the benefit of fields as diverse as human–computer interaction, kinesiology, motor rehabilitation, etc.', None, 'This paper presents a novel orientation algorithm designed to support a computationally efficient, wearable inertial human motion tracking system for rehabilitation applications. It is applicable to inertial measurement units (IMUs) consisting of tri-axis gyroscopes and accelerometers, and magnetic angular rate and gravity (MARG) sensor arrays that also include tri-axis magnetometers. The MARG implementation incorporates magnetic distortion compensation. The algorithm uses a quaternion representation, allowing accelerometer and magnetometer data to be used in an analytically derived and optimised gradient descent algorithm to compute the direction of the gyroscope measurement error as a quaternion derivative. Performance has been evaluated empirically using a commercially available orientation sensor and reference measurements of orientation obtained using an optical measurement system. Performance was also benchmarked against the propriety Kalman-based algorithm of orientation sensor. Results indicate the algorithm achieves levels of accuracy matching that of the Kalman based algorithm; < 0.8° static RMS error, < 1.7° dynamic RMS error. The implications of the low computational load and ability to operate at small sampling rates significantly reduces the hardware and power necessary for wearable inertial movement tracking, enabling the creation of lightweight, inexpensive systems capable of functioning for extended periods of time.', 'The optical flow sensor can detect the movement of the unmanned aerial vehicle (UAV) on the ground; thus, it is widely used for UAV flight control. The commonly used pinhole model of optical flow sensor describes the optical flow measurement in linear and angular velocities. It is not suitable in the case of discrete-time processing. A novel measurement model for the optical flow sensor is proposed, which directly gives the relationship between the optical flow and the UAV’s translational/angular motions in each sampling period. A data fusion scheme based on cubature transform is also presented, which can augment UAV’s position estimation using optical flow data. The proposed method is proven to be effective through flight tests on UAVs.', 'Aiming at the problem of the weak dynamic performance of the gradient descent method in the attitude and heading reference system, the susceptibility to the interference of accelerometers and magnetometers, and the complex calculation of the nonlinear Kalman Filter method, an extended Kalman filter suitable for a low-cost magnetic, angular rate, and gravity (MARG) sensor system is proposed. The method proposed in this paper is a combination of a two-stage gradient descent algorithm and the extended Kalman filter (GDEKF). First, the accelerometer and magnetometer are used to correct the attitude angle according to the two-stage gradient descent algorithm. The obtained attitude quaternion is combined with the gyroscope measurement value as the observation vector of EKF and the calculated attitude of the gyroscope and the bias of the gyroscope are corrected. The elimination of the bias of the gyroscope can further improve the stability of the attitude observation results. Finally, the MARG sensor system was designed for mathematical model simulation and hardware-in-the-loop simulation to verify the performance of the filter. The results show that compared with the gradient descent method, it has better anti-interference performance and dynamic performance, and better measurement accuracy than the extended Kalman filter.', 'Quadcopters are becoming increasingly popular across diverse sectors. Since rotor damages occur frequently, it is essential to improve the attitude estimation and thus ultimately the ability to control a damaged quadcopter. This research is based on a state-of-the-art method that makes it possible to control the quadcopter despite the total failure of a single rotor, where the attitude and position of the quadcopter are provided by an external system. In the present research, a novel attitude estimator called Adaptive Fuzzy Complementary Kalman Filter (AFCKF) has been developed and validated that works independently of any external systems. It is able to estimate the attitude of a quadcopter with one fully damaged rotor while only relying on the on-board MARG (Magnetometer, Accelerometer, Rate Gyroscope) sensors. The AFCKF provides significantly better attitude estimates for flights with a damaged rotor than mainstream filters, estimating the roll and pitch of the quadcopter with an RMS error of less than 1.7 degrees and a variance of less than 2 degrees. The proposed filter also provides accurate yaw estimates despite the fast spinning motion of the damaged quadcopter, and thus outperforms existing methods at the cost of only a small increase in computation.', 'The attitude estimation of a rigid body by magnetic, angular rate, and gravity (MARG) sensors is a research subject for a large variety of engineering applications. A standard solution for building up the observer is usually based on the Kalman filter and its different extensions for versatility and practical implementation. However, the performance of these observers has long suffered from the inaccurate process and measurement noise covariance matrices, which in turn entails tedious parameter turning procedures. To overcome the laborious noise covariance matrices regulation, we propose in this paper a Q-learning-based approach to autonomously adapt the values of process and measurement noise covariance matrices. The Q-learning method establishes a reinforcement learning mechanism that forces the noise covariance matrices pair with the least difference between predictions and measurements of output to be found in a predetermined candidate set of noise covariance matrices. The effectiveness of the Q-learning approach, applied to Extended Kalman filter-based attitude estimation, is validated through the Monte Carlo method that uses real flight data on an unmanned aerial vehicle.', 'The MARG sensor, which stands for the combination of a magnetometer, an accelerometer, and a gyroscope, is widely used for 3D attitude measurement. Among the mainstream solutions for MARG-based attitude estimation, the complementary filter (CF) is normally regarded as a simplified alternative to the Kalman filter (KF), mainly because CF can reduce the amount of calculations. A dual-vector discrete-time CF (DV-DTCF) and its tuning methods are introduced in this paper. Different from the quaternion-based attitude estimation algorithms, DV-DTCF has a linear measurement model, since it utilizes the gravity and geomagnetic vectors as its state variables instead of quaternions. This feature of DV-DTCF can avoid linearization error or the use of nonlinear algorithms, and can also greatly reduce its computational complexity. More interestingly, it is analytically revealed, and experimentally proven, that the proposed DV-DTCF is fully equivalent to a fixed-gain KF. This fascinating fact leads straightforwardly to the tuning methods of DV-DTCF via the corresponding fixed-gain KF and Riccati equation. These tuning methods of DV-DTCF are based on the statistic characteristics of MARG sensor noise, and that makes them solid and feasible. According to experimental results, DV-DTCF can achieve the same accuracy as that of commonly-used KF algorithms in MARG-based attitude estimation, but with much lower time consumption. Hence, the proposed DV-DTCF is especially suitable for applications that have strict limitations on computational costs.', 'In mechatronic-related applications, estimating orientation from a magnetic, angular rate, and gravity (MARG) sensor array is a significant topic. Representing attitude orientation is a well-known topic in the aerospace industry, where it plays a critical role in airplanes and unmanned aerial vehicles (UAVs), but it has also gained relevance in other sectors. However, most of the sensors utilized are quite expensive, heavy, and large, making them unsuitable for modest applications. This paper examines the performance of several sensors in low-cost hardware and high-acceleration environments. A theorical method was adopted to estimate Euler angles by using accelerometer, gyroscope and magnetometer, and a robust and easy to implement method calibration was proposed to calibrate the MARG sensor without any external equipment. An experimental verification of the proposed calibration method was completed. The experimental results are then interpreted to provide an insight to advantages and disadvantages for using each sensor separately.']\n"
     ]
    }
   ],
   "source": [
    "def rec(title):\n",
    "    match_url =  \"https://api.semanticscholar.org/graph/v1/paper/search/match\"\n",
    "    recommend_url = \"https://api.semanticscholar.org/recommendations/v1/papers/forpaper/\"\n",
    "    search_url = \"https://api.semanticscholar.org/graph/v1/paper/search\"\n",
    "    api_key = os.getenv(\"X_API_KEY\")\n",
    "    if not api_key:\n",
    "        print(\"API key is missing. Please set the X_API_KEY environment variable.\")\n",
    "    headers = {\n",
    "        \"x-api-key\": api_key,\n",
    "        \"Content-Type\": \"application/json\",\n",
    "    }\n",
    "    match_params = {\n",
    "        \"query\": title,\n",
    "        \"fields\": \"title\",\n",
    "        \"limit\": 1\n",
    "    }\n",
    "    title_match_response = requests.get(match_url, headers=headers, params=match_params)\n",
    "            \n",
    "    if title_match_response.status_code == 200:\n",
    "        # test\n",
    "        matched_title = title_match_response.json()['data'][0]['title']\n",
    "        paperId = title_match_response.json()['data'][0]['paperId']\n",
    "        # print(type(paperId))\n",
    "        # print(title, paperId)\n",
    "\n",
    "        # Get the exact paper in SS\n",
    "        if matched_title == title:\n",
    "\n",
    "            url=recommend_url+paperId    \n",
    "            params = {\n",
    "                \"fields\": \"abstract\",\n",
    "                \"limit\": 10,  \n",
    "            }\n",
    "\n",
    "            # Search for Recommended Papers\n",
    "            response = requests.get(url, headers=headers, params=params)\n",
    "            # Get recommended Papers\n",
    "            if response.status_code == 200:\n",
    "                recommended_papers = response.json()['recommendedPapers']\n",
    "\n",
    "                # Recommended Papers could be None\n",
    "                if recommended_papers:\n",
    "                    print(f'{len(recommended_papers)} founded')\n",
    "                    abstracts = [paper['abstract'] for paper in recommended_papers]\n",
    "                    # print(len(abstracts))\n",
    "                else: \n",
    "                    print('No related Paper!')\n",
    "                    return None\n",
    "            else:\n",
    "                print(f\"Error: {response.status_code} - {response.text}\")\n",
    "                return None\n",
    "        \n",
    "    # Not the same paper\n",
    "    else:\n",
    "        params = {\n",
    "            \"query\": title,\n",
    "            \"fields\": \"abstract\",\n",
    "            \"limit\": 10  # Number of results to retrieve\n",
    "        }\n",
    "\n",
    "        response = requests.get(search_url, headers=headers, params=params)\n",
    "        if response.status_code == 200:\n",
    "            entries = response.json()['data']\n",
    "            abstracts = [entry['abstract'] for entry in entries]\n",
    "            # print(len(abstracts))\n",
    "        else:\n",
    "            print(f\"Error: {response.status_code} - {response.text}\")\n",
    "            return None\n",
    "    return abstracts\n",
    "title = \"MARG\"\n",
    "\n",
    "print(rec(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the JSON output containing 10 diverse search inputs based on the provided research paper:\n",
      "\n",
      "{\"keywords\": [\n",
      "\"AI research impact academia vs industry\",\n",
      "\"Citation disruptiveness academic industry AI papers\",\n",
      "\"Novelty atypicality AI publications academia industry\",\n",
      "\"Academic-industry collaboration AI research outcomes\",\n",
      "\"State-of-the-art AI models academia vs industry\",\n",
      "\"Mixed-effects models AI research team composition\",\n",
      "\"AI conference publication trends academia industry\",\n",
      "\"Research team size impact AI publications\",\n",
      "\"Bibliometric analysis artificial intelligence research\",\n",
      "\"AI researcher mobility academia industry impact\"\n",
      "]}\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "model_id = \"anthropic.claude-3-5-sonnet-20240620-v1:0\"\n",
    "paper_path = \"../data/The complementary contributions of academia and industry to AI research.txt\"\n",
    "with open(paper_path, 'r') as file:\n",
    "    papercontent = file.read()\n",
    "system_prompt =[{\"text\":\"\"\"\n",
    "    You are an expert in academic research analysis and bibliometrics.\n",
    "    I will provide you with a research paper.\n",
    "    Your task is to generate 10 diverse and effective search inputs that could be used on academic search engines\n",
    "    to find similar or related work. These search inputs should cover various aspects of the paper,\n",
    "    including main concepts, methodologies, and unique features.\n",
    "    Analyze the given title and abstract thoroughly,\n",
    "    and then provide only the list of 10 search inputs in a JSON format like:\n",
    "    {\"keywords\": [\"string1\", \"string2\", \"string3\", ...]}\n",
    "    Provide no additional explanation or commentary, only the JSON output.\n",
    "\"\"\"}]\n",
    "\n",
    "bedrock_runtime = boto3.client(\"bedrock-runtime\")\n",
    "\n",
    "messages =[\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\":[{\n",
    "            \"text\":papercontent,\n",
    "        }],\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "response = bedrock_runtime.converse(\n",
    "    modelId=model_id,\n",
    "    messages=messages,\n",
    "    system=system_prompt\n",
    ")\n",
    "\n",
    "response_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
